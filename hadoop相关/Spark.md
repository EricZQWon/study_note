- [Spark](#spark)
# Spark
- 特点：Spark并不以MR作为执行引擎，而是使用了自己的分布式环境（DAG）。我们知道 **MR始终需要从磁盘中加载**，而 **Spark的工作数据集则是存储在内存中的**。这使得Spark的运行效率更高。并且Spark与Hadoop紧密集成，可以在Yarn上运行，并且支持HDFS的文件格式。
- 适用类型：
    1. 迭代算法：即对某一个数据集重复应用某一个函数，直至满足退出条件
    2. 交互式分析：**正好是MR的缺点**；我们知道MR因为从磁盘加载，因此运行时间较长，Spark弥补了这个缺点，它从内存中加载，因此适合面向用户的交互式。
- RDD(弹性分布式数据集):
    - 概念：是Spark中最核心的概念。是在集群中跨多个机器分区存储的一个 **只读对象集合**。 
- 与MR相比：
    1. Spark也有作业的概念，由任意的多阶段有向无环图（DAG） 构成，每个阶段可以类比为MR的map/reduce
    2. 每个阶段由可以分解为多个任务
    3. Spark的作业 **始终运行在应用上下文 _sparkContext_ 中**，它提供了RDD分组以及共享变量。一个应用可以串行/并行的运行呢多个作业。 
